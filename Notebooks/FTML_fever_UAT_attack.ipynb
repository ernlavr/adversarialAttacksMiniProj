{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tynrGPbjrWMB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7f500f1-3070-4bef-b2c6-3e2a0ab45625"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 KB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 KB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.0/300.0 KB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 KB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ligo-segments (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q gwpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvoTzuDI2DAj"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install git+https://github.com/ernlavr/OpenAttack.git\n",
        "!pip install nltk\n",
        "!pip install pytorch-crf\n",
        "!pip install language-tool-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYTNOwYEbctr"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import OpenAttack\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import numpy as np\n",
        "import datasets\n",
        "import transformers\n",
        "import torch\n",
        "import random\n",
        "from importlib import reload\n",
        "\n",
        "def enforce_reproducibility(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "enforce_reproducibility()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2_JZyuNm2hM",
        "outputId": "aaec1aad-e1f4-45cf-d1dc-8732c64984ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Attacker\n",
            "Build model\n"
          ]
        }
      ],
      "source": [
        "def dataset_mapping(x):\n",
        "    premise = x['premise']\n",
        "    hypothesis = x['hypothesis']\n",
        "    label = x['label']  \n",
        "    return {\n",
        "        \"x\": premise + \" \" + hypothesis,\n",
        "        \"y\": label,\n",
        "    }\n",
        "\n",
        "def balance_dataset(ds, numSamples=-1):\n",
        "    \"\"\"\n",
        "    Balances the dataset by removing samples\n",
        "    :param ds: The dataset\n",
        "    :param numSamples: The number of samples to keep per label\n",
        "    :return: The balanced indices\n",
        "    \"\"\"\n",
        "    # Get the number of samples for each label\n",
        "    dss = ds[:]\n",
        "    labels = dss[\"fever_gold_label\"]\n",
        "    if numSamples == -1:\n",
        "        numSamples = len(labels)\n",
        "        unique, counts = np.unique(labels, return_counts=True)\n",
        "        counts = np.roll(counts, 1)\n",
        "        unique = np.roll(unique, 1)\n",
        "        numSamples = min(counts)\n",
        "\n",
        "    # get indices of ds elements where ds['label'] is 0\n",
        "    arr = dss['label']\n",
        "    arr = np.array(arr)\n",
        "    indicesSup = np.where(arr == 0)[0][:numSamples]\n",
        "    indicesNei = np.where(arr == 1)[0][:numSamples]\n",
        "    indicesRef = np.where(arr == 2)[0][:numSamples]\n",
        "\n",
        "    # combine the indices\n",
        "    indices = np.sort((np.concatenate((indicesSup, indicesNei, indicesRef))))\n",
        "    indices = indices.tolist()\n",
        "    # get a subset of the dataset\n",
        "    return indices\n",
        "\n",
        "print(\"New Attacker\")\n",
        "print(\"Build model\")\n",
        "HG_MODEL_NAME = \"ernlavr/destilbert_uncased_fever_nli\"\n",
        "HG_DATASET = \"pietrolesci/nli_fever\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXZMF0MCm74m"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "# Load model, tokenizer and create an OpenAttack classifier\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(HG_MODEL_NAME)\n",
        "model = transformers.AutoModelForSequenceClassification.from_pretrained(HG_MODEL_NAME, output_hidden_states=True)\n",
        "clsf = OpenAttack.classifiers.TransformersClassifier(model, tokenizer=tokenizer, embedding_layer=model.base_model.embeddings.word_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmu8J-GDm_Ui"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Load, map and balance the dataset as per fine-tuning\n",
        "ds = datasets.load_dataset(HG_DATASET)\n",
        "dataset = ds['dev'].map(function=dataset_mapping)\n",
        "dsIndices = balance_dataset(dataset, 30)\n",
        "devSet = torch.utils.data.Subset(dataset, dsIndices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvL2kc6znIR6"
      },
      "source": [
        "## Certificate Issues\n",
        "Below is the loop for using UAT attack. There seems to be a problem with the certificates so if you need to re-run this then copy+paste the bottom code in zip_downloader.py (access it from the callstack)\n",
        "\n",
        "\n",
        "```\n",
        "/usr/local/lib/python3.8/dist-packages/OpenAttack/utils/zip_downloader.py \n",
        "\n",
        "ctx = ssl.create_default_context()\n",
        "ctx.check_hostname = False\n",
        "ctx.verify_mode = ssl.CERT_NONE\n",
        "\n",
        "with urllib.request.urlopen(remote_url, context=ctx) as fin:\n",
        "```\n",
        "\n",
        "## Universal Adversarial Trigger bug\n",
        "There also seems to be a bug in the original code that is downloaded as a pip package. For some reason pip doesn't download the most recent OpenAttack, so you need to manually integrate this commit\n",
        "https://github.com/thunlp/OpenAttack/commit/50606c3acd1e1ac192fcc2f80997580f274c5ae2\n",
        "\n",
        "On Colab its located in\n",
        "```\n",
        "/usr/local/lib/python3.8/dist-packages/OpenAttack/attackers/uat/__init__.py\n",
        "```\n",
        "## IMPORTANT\n",
        "Afterwards re-run the import cell!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysjjE4E-nAb1",
        "outputId": "c23d20c6-82dd-44db-90ee-483dede296ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialize some mad hacks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading TProcess.NLTKSentTokenizer: 100%|██████████| 162k/162k [00:00<00:00, 324kB/s]\n",
            "Downloading TProcess.NLTKPerceptronPosTagger: 100%|██████████| 2.53M/2.53M [00:01<00:00, 2.20MB/s]\n",
            "Epoch 0: 100%|██████████| 900/900 [13:05<00:00,  1.15it/s]\n",
            "Epoch 1: 100%|██████████| 900/900 [13:04<00:00,  1.15it/s]\n"
          ]
        }
      ],
      "source": [
        "# Proceed to attacking (rawr)\n",
        "print(\"Initialize some mad hacks\")\n",
        "attacker = OpenAttack.attackers.UATAttacker()\n",
        "attacker.set_triggers(clsf, devSet, beam_size=3, epoch=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQ9zGJlbnCC2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2488aeb3-ef2f-4522-beb0-490f1edf55f5"
      },
      "outputs": [],
      "source": [
        "print(\"Start some mad hacks\")\n",
        "attack_eval = OpenAttack.AttackEval( attacker, clsf, metrics=[\n",
        "    OpenAttack.metric.Fluency(),\n",
        "    OpenAttack.metric.GrammaticalErrors(),\n",
        "    OpenAttack.metric.EditDistance(),\n",
        "    OpenAttack.metric.ModificationRate()\n",
        "] )\n",
        "attack_eval.eval(devSet, visualize=True, progress_bar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1q-GHHjpAab"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}